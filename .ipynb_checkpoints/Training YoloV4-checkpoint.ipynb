{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 02 19:14:33 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 2070   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8     6W /  N/A |    578MiB /  8192MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4180    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10024    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     14596    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     15404    C+G   ...ekyb3d8bbwe\\commsapps.exe    N/A      |\n",
      "|    0   N/A  N/A     15488    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18132    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     20288    C+G   ...es.TextInput.InputApp.exe    N/A      |\n",
      "|    0   N/A  N/A     21868    C+G   ...4__8wekyb3d8bbwe\\Time.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'darknet'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/roboflow-ai/darknet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\VehicleDetection\\darknet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%rm` not found.\n"
     ]
    }
   ],
   "source": [
    "%cd darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU=1\n",
      "CUDNN=1\n",
      "CUDNN_HALF=0\n",
      "OPENCV=1\n",
      "AVX=0\n",
      "OPENMP=0\n",
      "LIBSO=0\n",
      "ZED_CAMERA=0 # ZED SDK 3.0 and above\n",
      "ZED_CAMERA_v2_8=0 # ZED SDK 2.X\n",
      "\n",
      "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
      "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n",
      "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
      "\n",
      "USE_CPP=0\n",
      "DEBUG=0\n",
      "\n",
      "ARCH= -gencode arch=compute_30,code=sm_30 \\\n",
      "      -gencode arch=compute_35,code=sm_35 \\\n",
      "      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
      "      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
      "\t  -gencode arch=compute_61,code=[sm_61,compute_61]\n",
      "\n",
      "OS := $(shell uname)\n",
      "\n",
      "# Tesla V100\n",
      "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
      "\n",
      "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
      "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
      "\n",
      "# Jetson XAVIER\n",
      "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
      "\n",
      "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
      "# ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61\n",
      "\n",
      "# GP100/Tesla P100 - DGX-1\n",
      "ARCH= -gencode arch=compute_60,code=sm_60\n",
      "\n",
      "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
      "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
      "\n",
      "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
      "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
      "\n",
      "\n",
      "VPATH=./src/\n",
      "EXEC=darknet\n",
      "OBJDIR=./obj/\n",
      "\n",
      "ifeq ($(LIBSO), 1)\n",
      "LIBNAMESO=libdarknet.so\n",
      "APPNAMESO=uselib\n",
      "endif\n",
      "\n",
      "ifeq ($(USE_CPP), 1)\n",
      "CC=g++\n",
      "else\n",
      "CC=gcc\n",
      "endif\n",
      "\n",
      "CPP=g++ -std=c++11\n",
      "NVCC=nvcc\n",
      "OPTS=-Ofast\n",
      "LDFLAGS= -lm -pthread\n",
      "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
      "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n",
      "\n",
      "ifeq ($(DEBUG), 1)\n",
      "#OPTS= -O0 -g\n",
      "#OPTS= -Og -g\n",
      "COMMON+= -DDEBUG\n",
      "CFLAGS+= -DDEBUG\n",
      "else\n",
      "ifeq ($(AVX), 1)\n",
      "CFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
      "endif\n",
      "endif\n",
      "\n",
      "CFLAGS+=$(OPTS)\n",
      "\n",
      "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
      "LDFLAGS+=-lws2_32\n",
      "endif\n",
      "\n",
      "ifeq ($(OPENCV), 1)\n",
      "COMMON+= -DOPENCV\n",
      "CFLAGS+= -DOPENCV\n",
      "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
      "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
      "endif\n",
      "\n",
      "ifeq ($(OPENMP), 1)\n",
      "CFLAGS+= -fopenmp\n",
      "LDFLAGS+= -lgomp\n",
      "endif\n",
      "\n",
      "ifeq ($(GPU), 1)\n",
      "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
      "CFLAGS+= -DGPU\n",
      "ifeq ($(OS),Darwin) #MAC\n",
      "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
      "else\n",
      "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
      "endif\n",
      "endif\n",
      "\n",
      "ifeq ($(CUDNN), 1)\n",
      "COMMON+= -DCUDNN\n",
      "ifeq ($(OS),Darwin) #MAC\n",
      "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
      "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
      "else\n",
      "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
      "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
      "endif\n",
      "endif\n",
      "\n",
      "ifeq ($(CUDNN_HALF), 1)\n",
      "COMMON+= -DCUDNN_HALF\n",
      "CFLAGS+= -DCUDNN_HALF\n",
      "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
      "endif\n",
      "\n",
      "ifeq ($(ZED_CAMERA), 1)\n",
      "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
      "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
      "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
      "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0 \n",
      "else\n",
      "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
      "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0 \n",
      "endif\n",
      "endif\n",
      "\n",
      "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
      "ifeq ($(GPU), 1) \n",
      "LDFLAGS+= -lstdc++ \n",
      "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
      "endif\n",
      "\n",
      "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
      "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
      "\n",
      "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
      "\n",
      "ifeq ($(LIBSO), 1)\n",
      "CFLAGS+= -fPIC\n",
      "\n",
      "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
      "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
      "\n",
      "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
      "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
      "endif\n",
      "\n",
      "$(EXEC): $(OBJS)\n",
      "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
      "\n",
      "$(OBJDIR)%.o: %.c $(DEPS)\n",
      "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
      "\n",
      "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
      "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
      "\n",
      "$(OBJDIR)%.o: %.cu $(DEPS)\n",
      "\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n",
      "\n",
      "$(OBJDIR):\n",
      "\tmkdir -p $(OBJDIR)\n",
      "backup:\n",
      "\tmkdir -p backup\n",
      "results:\n",
      "\tmkdir -p results\n",
      "setchmod:\n",
      "\tchmod +x *.sh\n",
      "\n",
      ".PHONY: clean\n",
      "\n",
      "clean:\n",
      "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n"
     ]
    }
   ],
   "source": [
    "!cat Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Datasets\\Soft Computing\\darknet\n"
     ]
    }
   ],
   "source": [
    "%cd darknet/\n",
    "with open('data/obj.data', 'w') as out:\n",
    "  out.write('classes = 9\\n')\n",
    "  out.write('train = data/train.txt\\n')\n",
    "  out.write('valid = data/valid.txt\\n')\n",
    "  out.write('names = data/obj.names\\n')\n",
    "  out.write('backup = backup/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write train file (just the image list)\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/train.txt', 'w') as out:\n",
    "  for img in [f for f in os.listdir('./data/obj') if f.endswith('jpg')]:\n",
    "    out.write('data/obj/' + img + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train/_darknet.labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e5d93a3c3905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train/_darknet.labels'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"writing config for a custom YOLOv4 detector detecting number of classes: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-e5d93a3c3905>\u001b[0m in \u001b[0;36mfile_len\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfile_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/_darknet.labels'"
     ]
    }
   ],
   "source": [
    "#we build config dynamically based on number of classes\n",
    "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
    "def file_len(fname):\n",
    "  with open(fname) as f:\n",
    "    for i, l in enumerate(f):\n",
    "      pass\n",
    "  return i + 1\n",
    "\n",
    "num_classes = file_len('train/_darknet.labels')\n",
    "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
    "\n",
    "#Instructions from the darknet repo\n",
    "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
    "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
    "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
    "\n",
    "\n",
    "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
    "  f.write('[net]' + '\\n')\n",
    "  f.write('batch=64' + '\\n')\n",
    "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
    "  f.write('subdivisions=24' + '\\n')\n",
    "  f.write('width=416' + '\\n')\n",
    "  f.write('height=416' + '\\n')\n",
    "  f.write('channels=3' + '\\n')\n",
    "  f.write('momentum=0.949' + '\\n')\n",
    "  f.write('decay=0.0005' + '\\n')\n",
    "  f.write('angle=0' + '\\n')\n",
    "  f.write('saturation = 1.5' + '\\n')\n",
    "  f.write('exposure = 1.5' + '\\n')\n",
    "  f.write('hue = .1' + '\\n')\n",
    "  f.write('\\n')\n",
    "  f.write('learning_rate=0.001' + '\\n')\n",
    "  f.write('burn_in=1000' + '\\n')\n",
    "  ######you can adjust up and down to change training time#####\n",
    "  ##Darknet does iterations with batches, not epochs####\n",
    "  max_batches = num_classes*2000\n",
    "  #max_batches = 2000\n",
    "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
    "  f.write('policy=steps' + '\\n')\n",
    "  steps1 = .8 * max_batches\n",
    "  steps2 = .9 * max_batches\n",
    "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
    "\n",
    "#Instructions from the darknet repo\n",
    "#change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
    "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
    "\n",
    "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
    "    content = f2.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 0,1,2' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "\n",
    "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
    "    content = f3.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 3,4,5' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "\n",
    "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
    "    content = f4.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 6,7,8' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "    \n",
    "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
    "    content = f5.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)\n",
    "\n",
    "print(\"file is written!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
    "    f.write('[net]' + '\\n')\n",
    "    f.write('batch=64' + '\\n')\n",
    "    #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
    "    f.write('subdivisions=24' + '\\n')\n",
    "    f.write('width=416' + '\\n')\n",
    "    f.write('height=416' + '\\n')\n",
    "    f.write('channels=3' + '\\n')\n",
    "    f.write('momentum=0.949' + '\\n')\n",
    "    f.write('decay=0.0005' + '\\n')\n",
    "    f.write('angle=0' + '\\n')\n",
    "    f.write('saturation = 1.5' + '\\n')\n",
    "    f.write('exposure = 1.5' + '\\n')\n",
    "    f.write('hue = .1' + '\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('learning_rate=0.001' + '\\n')\n",
    "    f.write('burn_in=1000' + '\\n')\n",
    "    ######you can adjust up and down to change training time#####\n",
    "    ##Darknet does iterations with batches, not epochs####\n",
    "    max_batches = num_classes*2000\n",
    "    #max_batches = 2000\n",
    "    f.write('max_batches=' + str(max_batches) + '\\n')\n",
    "    f.write('policy=steps' + '\\n')\n",
    "    steps1 = .8 * max_batches\n",
    "    steps2 = .9 * max_batches\n",
    "    f.write('steps='+str(steps1)+','+str(steps2) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[net]\n",
      "batch=64\n",
      "subdivisions=24\n",
      "width=416\n",
      "height=416\n",
      "channels=3\n",
      "momentum=0.949\n",
      "decay=0.0005\n",
      "angle=0\n",
      "saturation = 1.5\n",
      "exposure = 1.5\n",
      "hue = .1\n",
      "\n",
      "learning_rate=0.001\n",
      "burn_in=1000\n",
      "max_batches=12000\n",
      "policy=steps\n",
      "steps=9600.0,10800.0\n",
      "scales=.1,.1\n",
      "\n",
      "#cutmix=1\n",
      "mosaic=1\n",
      "\n",
      "#:104x104 54:52x52 85:26x26 104:13x13 for 416\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=32\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -2\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=32\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -1,-7\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -2\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=64\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -1,-10\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -2\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -1,-28\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -2\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -1,-28\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "# Downsample\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -2\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=linear\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "[route]\n",
      "layers = -1,-16\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=1024\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=mish\n",
      "\n",
      "##########################\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "### SPP ###\n",
      "[maxpool]\n",
      "stride=1\n",
      "size=5\n",
      "\n",
      "[route]\n",
      "layers=-2\n",
      "\n",
      "[maxpool]\n",
      "stride=1\n",
      "size=9\n",
      "\n",
      "[route]\n",
      "layers=-4\n",
      "\n",
      "[maxpool]\n",
      "stride=1\n",
      "size=13\n",
      "\n",
      "[route]\n",
      "layers=-1,-3,-5,-6\n",
      "### End SPP ###\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[upsample]\n",
      "stride=2\n",
      "\n",
      "[route]\n",
      "layers = 85\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[route]\n",
      "layers = -1, -3\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[upsample]\n",
      "stride=2\n",
      "\n",
      "[route]\n",
      "layers = 54\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[route]\n",
      "layers = -1, -3\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=128\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "##########################\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=33\n",
      "activation=linear\n",
      "\n",
      "[yolo]\n",
      "mask = 0,1,2\n",
      "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
      "classes=6\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .7\n",
      "truth_thresh = 1\n",
      "scale_x_y = 1.2\n",
      "iou_thresh=0.213\n",
      "cls_normalizer=1.0\n",
      "iou_normalizer=0.07\n",
      "iou_loss=ciou\n",
      "nms_kind=greedynms\n",
      "beta_nms=0.6\n",
      "max_delta=5\n",
      "\n",
      "\n",
      "[route]\n",
      "layers = -4\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "filters=256\n",
      "activation=leaky\n",
      "\n",
      "[route]\n",
      "layers = -1, -16\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=256\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=33\n",
      "activation=linear\n",
      "\n",
      "[yolo]\n",
      "mask = 3,4,5\n",
      "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
      "classes=6\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .7\n",
      "truth_thresh = 1\n",
      "scale_x_y = 1.1\n",
      "iou_thresh=0.213\n",
      "cls_normalizer=1.0\n",
      "iou_normalizer=0.07\n",
      "iou_loss=ciou\n",
      "nms_kind=greedynms\n",
      "beta_nms=0.6\n",
      "max_delta=5\n",
      "\n",
      "\n",
      "[route]\n",
      "layers = -4\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "filters=512\n",
      "activation=leaky\n",
      "\n",
      "[route]\n",
      "layers = -1, -37\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "filters=512\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "batch_normalize=1\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "filters=1024\n",
      "activation=leaky\n",
      "\n",
      "[convolutional]\n",
      "size=1\n",
      "stride=1\n",
      "pad=1\n",
      "filters=33\n",
      "activation=linear\n",
      "\n",
      "[yolo]\n",
      "mask = 6,7,8\n",
      "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
      "classes=6\n",
      "num=9\n",
      "jitter=.3\n",
      "ignore_thresh = .7\n",
      "truth_thresh = 1\n",
      "random=1\n",
      "scale_x_y = 1.05\n",
      "iou_thresh=0.213\n",
      "cls_normalizer=1.0\n",
      "iou_normalizer=0.07\n",
      "iou_loss=ciou\n",
      "nms_kind=greedynms\n",
      "beta_nms=0.6\n",
      "max_delta=5\n"
     ]
    }
   ],
   "source": [
    "!cat cfg/custom-yolov4-detector.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!darknet.exe detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
